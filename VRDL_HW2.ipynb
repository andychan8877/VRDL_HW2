{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VRDL_HW2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXkadM7QwRHG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb16def3-9782-4e4e-88b6-af00a2c41f4d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHBLJc4Do9sD"
      },
      "source": [
        "import os\n",
        "os.chdir('/content')\n",
        "!rm -rf mmdetection\n",
        "!rm -rf 2021VRDL_HW2_test\n",
        "!rm -rf 2021VRDL_HW2_train\n",
        "!rm -rf 2021VRDL_HW2_test.zip\n",
        "!rm -rf 2021VRDL_HW2_train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gyUNmrDm6Jy",
        "outputId": "487749b6-f82f-47dd-8787-f2af115af2bd"
      },
      "source": [
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "os.chdir('/content/mmdetection')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mmdetection'...\n",
            "remote: Enumerating objects: 21781, done.\u001b[K\n",
            "remote: Total 21781 (delta 0), reused 0 (delta 0), pack-reused 21781\u001b[K\n",
            "Receiving objects: 100% (21781/21781), 25.19 MiB | 22.99 MiB/s, done.\n",
            "Resolving deltas: 100% (15297/15297), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UzDXavswRkZ"
      },
      "source": [
        "!mkdir 2021VRDL_HW2\n",
        "os.chdir('/content/mmdetection/2021VRDL_HW2')\n",
        "\n",
        "# Google Drive\n",
        "!gdown --id '17lo71EG_RgAMS8o7AdaWEzzCSvsyOGCE' --output 2021VRDL_HW2_train.zip\n",
        "!gdown --id '1_xCyNxYeaByDtyihPVv0OCZ5svp2NLKp' --output 2021VRDL_HW2_test.zip\n",
        "\n",
        "!apt-get install unzi\n",
        "\n",
        "!unzip '2021VRDL_HW2_train.zip' -d 2021VRDL_HW2_train\n",
        "!unzip '2021VRDL_HW2_test.zip' -d 2021VRDL_HW2_test\n",
        "\n",
        "# os.chdir(\"/content/2021VRDL_HW1_datasets/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmRNvWPOwcpe"
      },
      "source": [
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from six.moves import cPickle as pickle\n",
        "\n",
        "# !git clone --recursive https://github.com/cupy/cupy.git\n",
        "# !cd cupy\n",
        "# !pip install .\n",
        "\n",
        "# import cupy as cp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B528NdDEp89N"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/mmdetection')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ppn6m0grB8v",
        "outputId": "c9ec4ecf-277d-498e-e8dc-6a3dc1843469"
      },
      "source": [
        "!pip install -r requirements/build.txt\n",
        "!pip install \"git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\"\n",
        "!pip install -v -e .  # or \"python setup.py develop\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r requirements/build.txt (line 2)) (0.29.24)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements/build.txt (line 3)) (1.19.5)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-yrlrdg4m\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-yrlrdg4m\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (57.4.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (0.29.24)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=263925 sha256=8543d5c6fb28458df0628ff3c5ead0160ed048746d7ebae15ec7f7f1b33322cc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q8tgsz28/wheels/e2/6b/1d/344ac773c7495ea0b85eb228bc66daec7400a143a92d36b7b1\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.2\n",
            "    Uninstalling pycocotools-2.0.2:\n",
            "      Successfully uninstalled pycocotools-2.0.2\n",
            "Successfully installed pycocotools-2.0\n",
            "Using pip 21.1.3 from /usr/local/lib/python3.7/dist-packages/pip (python 3.7)\n",
            "Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/include/python3.7/UNKNOWN\n",
            "sysconfig: /usr/include/python3.7m/UNKNOWN\n",
            "Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/bin\n",
            "sysconfig: /usr/bin\n",
            "Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local\n",
            "sysconfig: /usr\n",
            "Additional context:\n",
            "user = False\n",
            "home = None\n",
            "root = None\n",
            "prefix = None\n",
            "Non-user install because site-packages writeable\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-2axndwf2\n",
            "Created temporary directory: /tmp/pip-req-tracker-nkmxxbqn\n",
            "Initialized build tracking at /tmp/pip-req-tracker-nkmxxbqn\n",
            "Created build tracker: /tmp/pip-req-tracker-nkmxxbqn\n",
            "Entered build tracker: /tmp/pip-req-tracker-nkmxxbqn\n",
            "Created temporary directory: /tmp/pip-install-qcitp31p\n",
            "Obtaining file:///content/mmdetection\n",
            "  Added file:///content/mmdetection to build tracker '/tmp/pip-req-tracker-nkmxxbqn'\n",
            "    Running setup.py (path:/content/mmdetection/setup.py) egg_info for package from file:///content/mmdetection\n",
            "    Created temporary directory: /tmp/pip-pip-egg-info-xrsvgyua\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-pip-egg-info-xrsvgyua/mmdet.egg-info\n",
            "    writing /tmp/pip-pip-egg-info-xrsvgyua/mmdet.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-pip-egg-info-xrsvgyua/mmdet.egg-info/dependency_links.txt\n",
            "    writing requirements to /tmp/pip-pip-egg-info-xrsvgyua/mmdet.egg-info/requires.txt\n",
            "    writing top-level names to /tmp/pip-pip-egg-info-xrsvgyua/mmdet.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-xrsvgyua/mmdet.egg-info/SOURCES.txt'\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    warning: no files found matching 'mmdet/VERSION'\n",
            "    warning: no files found matching 'mmdet/.mim/model-index.yml'\n",
            "    warning: no files found matching 'mmdet/.mim/demo/*/*'\n",
            "    warning: no files found matching '*.py' under directory 'mmdet/.mim/configs'\n",
            "    warning: no files found matching '*.yml' under directory 'mmdet/.mim/configs'\n",
            "    warning: no files found matching '*.sh' under directory 'mmdet/.mim/tools'\n",
            "    warning: no files found matching '*.py' under directory 'mmdet/.mim/tools'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-xrsvgyua/mmdet.egg-info/SOURCES.txt'\n",
            "  Source in /content/mmdetection has version 2.18.1, which satisfies requirement mmdet==2.18.1 from file:///content/mmdetection\n",
            "  Removed mmdet==2.18.1 from file:///content/mmdetection from build tracker '/tmp/pip-req-tracker-nkmxxbqn'\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmdet==2.18.1) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet==2.18.1) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmdet==2.18.1) (1.15.0)\n",
            "1 location(s) to search for versions of terminaltables:\n",
            "* https://pypi.org/simple/terminaltables/\n",
            "Fetching project page and analyzing links: https://pypi.org/simple/terminaltables/\n",
            "Getting page https://pypi.org/simple/terminaltables/\n",
            "Found index url https://pypi.org/simple\n",
            "Looking up \"https://pypi.org/simple/terminaltables/\" in the cache\n",
            "Request header has \"max_age\" as 0, cache bypassed\n",
            "Starting new HTTPS connection (1): pypi.org:443\n",
            "https://pypi.org:443 \"GET /simple/terminaltables/ HTTP/1.1\" 200 1231\n",
            "Updating cache with response from \"https://pypi.org/simple/terminaltables/\"\n",
            "Caching due to etag\n",
            "  Found link https://files.pythonhosted.org/packages/ec/82/6390ba7f110622d27b02451aaa294dc4b3133b7661e464db9a116e977324/terminaltables-1.0.0.tar.gz#sha256=4c909a5ee4a3d028b2c977d996f8b8cd9724ce8e4d9d834d65e78a98f7965b54 (from https://pypi.org/simple/terminaltables/), version: 1.0.0\n",
            "  Found link https://files.pythonhosted.org/packages/97/65/858bc3ea6cc60edc959ce427a94227932b5d9a95b0bce82f16071419885c/terminaltables-1.0.1.tar.gz#sha256=5548ac567d38d6ac88a5e0fec2d95f646249f37e1ef8fd2d17f8fcaefc6cf592 (from https://pypi.org/simple/terminaltables/), version: 1.0.1\n",
            "  Found link https://files.pythonhosted.org/packages/82/42/3f1140f6e538582fd514c765244662cca60885048cf610e7d00eaee8aeb1/terminaltables-1.0.2.tar.gz#sha256=cf97dd019af975cc64aa69aca435a43b0cffabb88df6f337c6b48de600c19f8e (from https://pypi.org/simple/terminaltables/), version: 1.0.2\n",
            "  Found link https://files.pythonhosted.org/packages/80/07/5663569dfd8fa4e4fa3cb645b70f4972e3d79d056b71da12df174668c145/terminaltables-1.1.0.tar.gz#sha256=94a15e1a295265d130de67e9c2efef9e1cad1e64dd6ae0b80882076581605f8c (from https://pypi.org/simple/terminaltables/), version: 1.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/0c/4a/9b80642ac2463908fe77c9dbe138c56902fbf5a5a95d07203c131ec9ba90/terminaltables-1.1.1.tar.gz#sha256=b02c516d6d521ce0fe6e2a2753268e86547bbccab6bfa7e269a0f51766283fab (from https://pypi.org/simple/terminaltables/), version: 1.1.1\n",
            "  Found link https://files.pythonhosted.org/packages/a8/65/f9c6bcfb1f81acdfcd1f8d633c6752cfdcc04b5fade7638a2a8dc7a720de/terminaltables-1.2.0.tar.gz#sha256=fff4aa62f296038d1526a91856f0b3de1e3bce31cfd1c5148cc3f795c1d396bf (from https://pypi.org/simple/terminaltables/), version: 1.2.0\n",
            "  Found link https://files.pythonhosted.org/packages/3d/17/14aa6521b337be46c51dd7b31e7e617801e9f8db7f48583c767c02e0e72a/terminaltables-1.2.1.tar.gz#sha256=cf5f0fb6c6c3070d7af73537ded030858c122f253c87e7221f9a6da3782ce787 (from https://pypi.org/simple/terminaltables/), version: 1.2.1\n",
            "  Found link https://files.pythonhosted.org/packages/d0/8e/9403573ff8aebc09ee0aacd57885050f74bd9f48a85c0735d33cacfa2469/terminaltables-2.0.0.tar.gz#sha256=2e0a6688071f2a881f8fa4455a362457dcd2317e374609f1a09baffa998e7492 (from https://pypi.org/simple/terminaltables/), version: 2.0.0\n",
            "  Found link https://files.pythonhosted.org/packages/10/da/9bbb21c1c2f9be4df2056b00b569689b9ece538ef39bf8db34be25f9e850/terminaltables-2.1.0.tar.gz#sha256=33b60f027964214f4ff5821f43958d03add81784f7c183d86a7ee8f010350cf5 (from https://pypi.org/simple/terminaltables/), version: 2.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/58/c9/f0c174c4e828365df3593c66ac32474cd994a8ec36fe19a798261c96c3bc/terminaltables-3.0.0.tar.gz#sha256=bd2504031f09f942a8f221266adc61aee04a0368d5de0dacb7a53e508af6a518 (from https://pypi.org/simple/terminaltables/), version: 3.0.0\n",
            "  Found link https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from https://pypi.org/simple/terminaltables/), version: 3.1.0\n",
            "Skipping link: not a file: https://pypi.org/simple/terminaltables/\n",
            "Given no hashes to check 11 links for project 'terminaltables': discarding no candidates\n",
            "Collecting terminaltables\n",
            "  Created temporary directory: /tmp/pip-unpack-q198vqed\n",
            "  Looking up \"https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\" in the cache\n",
            "  No cache entry available\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz HTTP/1.1\" 200 12478\n",
            "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\n",
            "  Ignoring unknown cache-control directive: immutable\n",
            "  Updating cache with response from \"https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\"\n",
            "  Caching due to etag\n",
            "  Added terminaltables from https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from mmdet==2.18.1) to build tracker '/tmp/pip-req-tracker-nkmxxbqn'\n",
            "    Running setup.py (path:/tmp/pip-install-qcitp31p/terminaltables_7914a72b8ee84f6b889d3e5b0bd7d523/setup.py) egg_info for package terminaltables\n",
            "    Created temporary directory: /tmp/pip-pip-egg-info-cq7x3uem\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-pip-egg-info-cq7x3uem/terminaltables.egg-info\n",
            "    writing /tmp/pip-pip-egg-info-cq7x3uem/terminaltables.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-pip-egg-info-cq7x3uem/terminaltables.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-pip-egg-info-cq7x3uem/terminaltables.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-cq7x3uem/terminaltables.egg-info/SOURCES.txt'\n",
            "    listing git files failed - pretending there aren't any\n",
            "    reading manifest file '/tmp/pip-pip-egg-info-cq7x3uem/terminaltables.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-cq7x3uem/terminaltables.egg-info/SOURCES.txt'\n",
            "  Source in /tmp/pip-install-qcitp31p/terminaltables_7914a72b8ee84f6b889d3e5b0bd7d523 has version 3.1.0, which satisfies requirement terminaltables from https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from mmdet==2.18.1)\n",
            "  Removed terminaltables from https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from mmdet==2.18.1) from build tracker '/tmp/pip-req-tracker-nkmxxbqn'\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmdet==2.18.1) (2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.18.1) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.18.1) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.18.1) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.18.1) (0.11.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools->mmdet==2.18.1) (0.29.24)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->mmdet==2.18.1) (57.4.0)\n",
            "Created temporary directory: /tmp/pip-unpack-x2zdisci\n",
            "Building wheels for collected packages: terminaltables\n",
            "  Created temporary directory: /tmp/pip-wheel-057977yq\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-057977yq\n",
            "  Running command /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-qcitp31p/terminaltables_7914a72b8ee84f6b889d3e5b0bd7d523/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-qcitp31p/terminaltables_7914a72b8ee84f6b889d3e5b0bd7d523/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-057977yq\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib\n",
            "  creating build/lib/terminaltables\n",
            "  copying terminaltables/__init__.py -> build/lib/terminaltables\n",
            "  copying terminaltables/ascii_table.py -> build/lib/terminaltables\n",
            "  copying terminaltables/build.py -> build/lib/terminaltables\n",
            "  copying terminaltables/github_table.py -> build/lib/terminaltables\n",
            "  copying terminaltables/terminal_io.py -> build/lib/terminaltables\n",
            "  copying terminaltables/base_table.py -> build/lib/terminaltables\n",
            "  copying terminaltables/other_tables.py -> build/lib/terminaltables\n",
            "  copying terminaltables/width_and_alignment.py -> build/lib/terminaltables\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/__init__.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/ascii_table.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/build.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/github_table.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/terminal_io.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/base_table.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/other_tables.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/width_and_alignment.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing terminaltables.egg-info/PKG-INFO\n",
            "  writing dependency_links to terminaltables.egg-info/dependency_links.txt\n",
            "  writing top-level names to terminaltables.egg-info/top_level.txt\n",
            "  listing git files failed - pretending there aren't any\n",
            "  reading manifest file 'terminaltables.egg-info/SOURCES.txt'\n",
            "  writing manifest file 'terminaltables.egg-info/SOURCES.txt'\n",
            "  Copying terminaltables.egg-info to build/bdist.linux-x86_64/wheel/terminaltables-3.1.0-py3.7.egg-info\n",
            "  running install_scripts\n",
            "  creating build/bdist.linux-x86_64/wheel/terminaltables-3.1.0.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-057977yq/terminaltables-3.1.0-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'terminaltables/__init__.py'\n",
            "  adding 'terminaltables/ascii_table.py'\n",
            "  adding 'terminaltables/base_table.py'\n",
            "  adding 'terminaltables/build.py'\n",
            "  adding 'terminaltables/github_table.py'\n",
            "  adding 'terminaltables/other_tables.py'\n",
            "  adding 'terminaltables/terminal_io.py'\n",
            "  adding 'terminaltables/width_and_alignment.py'\n",
            "  adding 'terminaltables-3.1.0.dist-info/METADATA'\n",
            "  adding 'terminaltables-3.1.0.dist-info/WHEEL'\n",
            "  adding 'terminaltables-3.1.0.dist-info/top_level.txt'\n",
            "  adding 'terminaltables-3.1.0.dist-info/zip-safe'\n",
            "  adding 'terminaltables-3.1.0.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15354 sha256=2dcd90decde651c0eaf9f33a9b199bcda13174d887f267a4cee22497c11f64ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/ad/c8/2d98360791161cd3db6daf6b5e730f34021fc9367d5879f497\n",
            "Successfully built terminaltables\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "  Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\n",
            "  Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\n",
            "  Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/terminaltables\n",
            "  sysconfig: /usr/include/python3.7m/terminaltables\n",
            "  Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\n",
            "  Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\n",
            "  Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\n",
            "\n",
            "  Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\n",
            "  Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\n",
            "  Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/mmdet\n",
            "  sysconfig: /usr/include/python3.7m/mmdet\n",
            "  Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\n",
            "  Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\n",
            "  Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\n",
            "  Running setup.py develop for mmdet\n",
            "    Running command /usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/content/mmdetection/setup.py'\"'\"'; __file__='\"'\"'/content/mmdetection/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\n",
            "    running develop\n",
            "    running egg_info\n",
            "    creating mmdet.egg-info\n",
            "    writing mmdet.egg-info/PKG-INFO\n",
            "    writing dependency_links to mmdet.egg-info/dependency_links.txt\n",
            "    writing requirements to mmdet.egg-info/requires.txt\n",
            "    writing top-level names to mmdet.egg-info/top_level.txt\n",
            "    writing manifest file 'mmdet.egg-info/SOURCES.txt'\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    warning: no files found matching 'mmdet/VERSION'\n",
            "    warning: no files found matching 'mmdet/.mim/demo/*/*'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file 'mmdet.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "    Creating /usr/local/lib/python3.7/dist-packages/mmdet.egg-link (link to .)\n",
            "    Adding mmdet 2.18.1 to easy-install.pth file\n",
            "\n",
            "    Installed /content/mmdetection\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:381: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "      warnings.warn(msg.format('we could not find ninja.'))\n",
            "Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/include/python3.7/UNKNOWN\n",
            "sysconfig: /usr/include/python3.7m/UNKNOWN\n",
            "Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/bin\n",
            "sysconfig: /usr/bin\n",
            "Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local\n",
            "sysconfig: /usr\n",
            "Additional context:\n",
            "user = False\n",
            "home = None\n",
            "root = None\n",
            "prefix = None\n",
            "Successfully installed mmdet-2.18.1 terminaltables-3.1.0\n",
            "Removed build tracker: '/tmp/pip-req-tracker-nkmxxbqn'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "7Ey_biZkqh0K",
        "outputId": "4ae08bd7-2411-4489-be2f-81e57538e535"
      },
      "source": [
        "# install Pillow 7.0.0 back in order to avoid bug in colab\n",
        "!pip install Pillow==7.0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Pillow==7.0.0\n",
            "  Downloading Pillow-7.0.0-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 7.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 7.0.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-7.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAfJBk40r0GS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97d633aa-a02d-4eff-ceba-fa560405541b"
      },
      "source": [
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html\n",
            "Collecting mmcv-full\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/mmcv_full-1.3.18-cp37-cp37m-manylinux1_x86_64.whl (58.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 58.0 MB 203 kB/s \n",
            "\u001b[?25hCollecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (4.1.2.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (21.3)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.31.0-py2.py3-none-any.whl (185 kB)\n",
            "\u001b[K     |████████████████████████████████| 185 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (7.0.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full) (3.0.6)\n",
            "Installing collected packages: yapf, addict, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.3.18 yapf-0.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHsWA8Lgrx2u"
      },
      "source": [
        "# SVHN extracts data from the digitStruct.mat full numbers files.  The data can be downloaded\n",
        "# the Street View House Number (SVHN)  web site: http://ufldl.stanford.edu/housenumbers.  \n",
        "#\n",
        "# This is an A2iA tweak (YG -9 Jan 2014) of the script found here :\n",
        "# http://blog.grimwisdom.com/python/street-view-house-numbers-svhn-and-octave\n",
        "#\n",
        "# The digitStruct.mat files in the full numbers tars (train.tar.gz, test.tar.gz, and extra.tar.gz) \n",
        "# are only compatible with matlab.  This Python program can be run at the command line and will generate \n",
        "# a json version of the dataset.\n",
        "#\n",
        "# Command line usage:\n",
        "#       SVHN_dataextract.py [-f input] [-o output_without_extension]\n",
        "#    >  python SVHN_dataextract.py -f digitStruct.mat -o digitStruct\n",
        "#\n",
        "# Issues:\n",
        "#    The alibility to split in several files has been removed from the original\n",
        "#    script.\n",
        "#\n",
        "\n",
        "import h5py\n",
        "import optparse\n",
        "from json import JSONEncoder\n",
        "\n",
        "import copy\n",
        "import os.path as osp\n",
        "\n",
        "import mmcv\n",
        "import numpy as np\n",
        "\n",
        "from mmdet.datasets.builder import DATASETS\n",
        "from mmdet.datasets.custom import CustomDataset\n",
        "\n",
        "parser = optparse.OptionParser()\n",
        "parser.add_option(\"-f\", dest=\"fin\", help=\"Matlab full number SVHN input file\", default=\"digitStruct.mat\")\n",
        "parser.add_option(\"-o\", dest=\"filePrefix\", help=\"name for the json output file\", default=\"digitStruct\")\n",
        "(options,args)= parser.parse_args()\n",
        "\n",
        "fin = options.fin\n",
        "\n",
        "# The DigitStructFile is just a wrapper around the h5py data.  It basically references \n",
        "#    inf:              The input h5 matlab file\n",
        "#    digitStructName   The h5 ref to all the file names\n",
        "#    digitStructBbox   The h5 ref to all struc data\n",
        "@DATASETS.register_module()\n",
        "class HW2_SVHN_Dataset(CustomDataset):\n",
        "\n",
        "    CLASSES = ('0.0', '1.0', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0', '8.0', '9.0', '10.0')\n",
        "    # getName returns the 'name' string for for the n(th) digitStruct. \n",
        "    def getName(self,n):\n",
        "        return ''.join([chr(c[0]) for c in self.inf[self.digitStructName[n][0]]])\n",
        "\n",
        "    # bboxHelper handles the coding difference when there is exactly one bbox or an array of bbox. \n",
        "    def bboxHelper(self,attr):\n",
        "        if (len(attr) > 1):\n",
        "            attr = [self.inf[attr[j].item()][0][0] for j in range(len(attr))]\n",
        "        else:\n",
        "            attr = [attr[0][0]]\n",
        "        return attr\n",
        "\n",
        "    # getBbox returns a dict of data for the n(th) bbox. \n",
        "    def getBbox(self,n):\n",
        "        bbox = {}\n",
        "        bb = self.digitStructBbox[n].item()\n",
        "        bbox['height'] = self.bboxHelper(self.inf[bb][\"height\"])\n",
        "        bbox['label'] = self.bboxHelper(self.inf[bb][\"label\"])\n",
        "        bbox['left'] = self.bboxHelper(self.inf[bb][\"left\"])\n",
        "        bbox['top'] = self.bboxHelper(self.inf[bb][\"top\"])\n",
        "        bbox['width'] = self.bboxHelper(self.inf[bb][\"width\"])\n",
        "        return bbox\n",
        "\n",
        "    def getDigitStructure(self,n):\n",
        "        s = self.getBbox(n)\n",
        "        s['name']=self.getName(n)\n",
        "        return s\n",
        "\n",
        "    # getAllDigitStructure returns all the digitStruct from the input file.     \n",
        "    def getAllDigitStructure(self):\n",
        "        return [self.getDigitStructure(i) for i in range(len(self.digitStructName))]\n",
        "\n",
        "    def load_annotations(self, ann_file):\n",
        "        self.inf = h5py.File(ann_file, 'r')\n",
        "        self.digitStructName = self.inf['digitStruct']['name']\n",
        "        self.digitStructBbox = self.inf['digitStruct']['bbox']\n",
        "\n",
        "        \n",
        "\n",
        "        cat2label = {k: i for i, k in enumerate(self.CLASSES)}\n",
        "\n",
        "        pictDat = self.getAllDigitStructure()\n",
        "        data_infos = []\n",
        "\n",
        "        for i in range(len(pictDat)):\n",
        "            filename = f'{self.img_prefix}/{pictDat[i][\"name\"]}'\n",
        "            # filename = '/content/mmdetection/2021VRDL_HW2/2021VRDL_HW2_train/train/' + pictDat[i][\"name\"]\n",
        "            image = mmcv.imread(filename)\n",
        "            height, width = image.shape[:2]\n",
        "            data_info = dict(filename=pictDat[i][\"name\"], width=width, height=height)\n",
        "\n",
        "            # annotations processing\n",
        "            bbox_names = [] # label包\n",
        "            for k in range(len(pictDat[i]['height'])):    \n",
        "               bbox_names.append(pictDat[i]['label'][k])\n",
        "            \n",
        "            bboxes = []\n",
        "            for j in range(len(pictDat[i]['height'])):\n",
        "               bbox = [] # 小的bbox包\n",
        "               bbox.append(pictDat[i]['left'][j])\n",
        "               bbox.append(pictDat[i]['top'][j])\n",
        "               bbox.append(pictDat[i]['width'][j])\n",
        "               bbox.append(pictDat[i]['height'][j])\n",
        "               bboxes.append(bbox)         \n",
        "\n",
        "            gt_bboxes = []\n",
        "            gt_labels = []\n",
        "            gt_bboxes_ignore = []\n",
        "            gt_labels_ignore = []\n",
        "    \n",
        "            # filter 'DontCare'\n",
        "            for bbox_name, bbox in zip(bbox_names, bboxes):\n",
        "                if str(bbox_name) in cat2label:\n",
        "                    gt_labels.append(cat2label[str(bbox_name)])\n",
        "                    gt_bboxes.append(bbox)\n",
        "                else:\n",
        "                    gt_labels_ignore.append(-1)\n",
        "                    gt_bboxes_ignore.append(bbox)\n",
        "            \n",
        "            data_anno = dict(\n",
        "                bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n",
        "                labels=np.array(gt_labels, dtype=np.long),\n",
        "                bboxes_ignore=np.array(gt_bboxes_ignore,\n",
        "                                       dtype=np.float32).reshape(-1, 4),\n",
        "                labels_ignore=np.array(gt_labels_ignore, dtype=np.long))\n",
        "\n",
        "            data_info.update(ann=data_anno)\n",
        "            data_infos.append(data_info)\n",
        "\n",
        "        return data_infos\n",
        "\n",
        "    def get_ann_info(self, idx):\n",
        "      return self.data_infos[idx]['ann']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm00d49YwjRb"
      },
      "source": [
        "from mmcv import Config\n",
        "# cfg = Config.fromfile('/content/mmdetection/configs/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_1x_coco.py')\n",
        "cfg = Config.fromfile('/content/mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtaBOfladIPm"
      },
      "source": [
        "lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMYx3kCErSfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03fcaefa-a8ff-4b03-a516-ceda71919117"
      },
      "source": [
        "import pathlib\n",
        "print(pathlib.Path().absolute())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mmdetection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwwkGE_UJBTJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd66fc98-27bb-4ba2-9dbe-385ae965731c"
      },
      "source": [
        "os.chdir('/content/mmdetection')\n",
        "!rm -rf checkpoints\n",
        "!mkdir checkpoints\n",
        "os.chdir('/content/mmdetection')\n",
        "!wget -c https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth \\\n",
        "      -O checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth\n",
        "!wget -c http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \\\n",
        "      -O checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
        "!wget -c https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_bbox_mAP-0.398_20200504_163323-30042637.pth \\\n",
        "      -O checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_bbox_mAP-0.398_20200504_163323-30042637.pth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-25 12:15:21--  https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 47.88.36.59\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|47.88.36.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 177867103 (170M) [application/octet-stream]\n",
            "Saving to: ‘checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth’\n",
            "\n",
            "checkpoints/mask_rc 100%[===================>] 169.63M  11.6MB/s    in 19s     \n",
            "\n",
            "2021-11-25 12:15:41 (9.14 MB/s) - ‘checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth’ saved [177867103/177867103]\n",
            "\n",
            "--2021-11-25 12:15:41--  http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 47.88.36.59\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|47.88.36.59|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 167287506 (160M) [application/octet-stream]\n",
            "Saving to: ‘checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth’\n",
            "\n",
            "checkpoints/faster_ 100%[===================>] 159.54M  12.6MB/s    in 13s     \n",
            "\n",
            "2021-11-25 12:15:55 (12.0 MB/s) - ‘checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth’ saved [167287506/167287506]\n",
            "\n",
            "--2021-11-25 12:15:55--  https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_bbox_mAP-0.398_20200504_163323-30042637.pth\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 47.88.36.59\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|47.88.36.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 167291065 (160M) [application/octet-stream]\n",
            "Saving to: ‘checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_bbox_mAP-0.398_20200504_163323-30042637.pth’\n",
            "\n",
            "checkpoints/faster_ 100%[===================>] 159.54M  11.5MB/s    in 14s     \n",
            "\n",
            "2021-11-25 12:16:11 (11.6 MB/s) - ‘checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_bbox_mAP-0.398_20200504_163323-30042637.pth’ saved [167291065/167291065]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlllaxU4Y7qf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2c2149f-c200-466f-86e5-3d4077ad426d"
      },
      "source": [
        "os.chdir('/content/mmdetection')\n",
        "from mmdet.apis import set_random_seed\n",
        "\n",
        "classes = ('0.0', '1.0', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0', '8.0', '9.0', '10.0')\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = 'HW2_SVHN_Dataset'\n",
        "cfg.data_root = '2021VRDL_HW2/'\n",
        "\n",
        "cfg.data.test.type = 'HW2_SVHN_Dataset'\n",
        "cfg.data.test.data_root = '2021VRDL_HW2/'\n",
        "cfg.data.test.ann_file = '2021VRDL_HW2_train/train/digitStruct.mat'\n",
        "cfg.data.test.img_prefix = '2021VRDL_HW2_test/test/'\n",
        "cfg.data.test.classes = classes\n",
        "\n",
        "cfg.data.train.type = 'HW2_SVHN_Dataset'\n",
        "cfg.data.train.data_root = '2021VRDL_HW2/'\n",
        "cfg.data.train.ann_file = '2021VRDL_HW2_train/train/digitStruct.mat'\n",
        "cfg.data.train.img_prefix = '2021VRDL_HW2_train/train/'\n",
        "cfg.data.train.classes = classes\n",
        "\n",
        "cfg.data.val.type = 'HW2_SVHN_Dataset'\n",
        "cfg.data.val.data_root = '2021VRDL_HW2/'\n",
        "cfg.data.val.ann_file = '2021VRDL_HW2_train/train/digitStruct.mat'\n",
        "cfg.data.val.img_prefix = '2021VRDL_HW2_train/train/'\n",
        "cfg.data.val.classes = classes\n",
        "\n",
        "# modify num classes of the model in box head\n",
        "cfg.model.roi_head.bbox_head.num_classes = 11\n",
        "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
        "# use the mask branch\n",
        "cfg.load_from = 'checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_bbox_mAP-0.398_20200504_163323-30042637.pth'  # noqa\n",
        "\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './tutorial_exps'\n",
        "\n",
        "# The original learning rate (LR) is set for 8-GPU training.\n",
        "# We divide it by 8 since we only use one GPU.\n",
        "cfg.optimizer.lr = 0.02 / 8\n",
        "cfg.lr_config.warmup = None\n",
        "cfg.log_config.interval = 10\n",
        "\n",
        "# Change the evaluation metric since we use customized dataset.\n",
        "cfg.evaluation.metric = 'mAP'\n",
        "# We can set the evaluation interval to reduce the evaluation times\n",
        "cfg.evaluation.interval = 3\n",
        "# We can set the checkpoint saving interval to reduce the storage cost\n",
        "cfg.checkpoint_config.interval = 3\n",
        "\n",
        "# Set seed thus the results are more reproducible\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "\n",
        "\n",
        "# We can initialize the logger for training and have a look\n",
        "# at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config:\n",
            "model = dict(\n",
            "    type='FasterRCNN',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        depth=50,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        norm_eval=True,\n",
            "        style='pytorch',\n",
            "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
            "    neck=dict(\n",
            "        type='FPN',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='StandardRoIHead',\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='SingleRoIExtractor',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32]),\n",
            "        bbox_head=dict(\n",
            "            type='Shared2FCBBoxHead',\n",
            "            in_channels=256,\n",
            "            fc_out_channels=1024,\n",
            "            roi_feat_size=7,\n",
            "            num_classes=11,\n",
            "            bbox_coder=dict(\n",
            "                type='DeltaXYWHBBoxCoder',\n",
            "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
            "            reg_class_agnostic=False,\n",
            "            loss_cls=dict(\n",
            "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
            "            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),\n",
            "    train_cfg=dict(\n",
            "        rpn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.3,\n",
            "                min_pos_iou=0.3,\n",
            "                match_low_quality=True,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=256,\n",
            "                pos_fraction=0.5,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=False),\n",
            "            allowed_border=-1,\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        rpn_proposal=dict(\n",
            "            nms_pre=2000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False)),\n",
            "    test_cfg=dict(\n",
            "        rpn=dict(\n",
            "            nms_pre=1000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            score_thr=0.05,\n",
            "            nms=dict(type='nms', iou_threshold=0.5),\n",
            "            max_per_img=100)))\n",
            "dataset_type = 'HW2_SVHN_Dataset'\n",
            "data_root = '2021VRDL_HW2/'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
            "    dict(type='RandomFlip', flip_ratio=0.5),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=(1333, 800),\n",
            "        flip=False,\n",
            "        transforms=[\n",
            "            dict(type='Resize', keep_ratio=True),\n",
            "            dict(type='RandomFlip'),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=2,\n",
            "    workers_per_gpu=2,\n",
            "    train=dict(\n",
            "        type='HW2_SVHN_Dataset',\n",
            "        ann_file='2021VRDL_HW2_train/train/digitStruct.mat',\n",
            "        img_prefix='2021VRDL_HW2_train/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=0.5),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "        ],\n",
            "        data_root='2021VRDL_HW2/',\n",
            "        classes=('0.0', '1.0', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0', '8.0',\n",
            "                 '9.0', '10.0')),\n",
            "    val=dict(\n",
            "        type='HW2_SVHN_Dataset',\n",
            "        ann_file='2021VRDL_HW2_train/train/digitStruct.mat',\n",
            "        img_prefix='2021VRDL_HW2_train/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1333, 800),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ],\n",
            "        data_root='2021VRDL_HW2/',\n",
            "        classes=('0.0', '1.0', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0', '8.0',\n",
            "                 '9.0', '10.0')),\n",
            "    test=dict(\n",
            "        type='HW2_SVHN_Dataset',\n",
            "        ann_file='2021VRDL_HW2_train/train/digitStruct.mat',\n",
            "        img_prefix='2021VRDL_HW2_test/test/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1333, 800),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ],\n",
            "        data_root='2021VRDL_HW2/',\n",
            "        classes=('0.0', '1.0', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0', '8.0',\n",
            "                 '9.0', '10.0')))\n",
            "evaluation = dict(interval=3, metric='mAP')\n",
            "optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=None)\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup=None,\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.001,\n",
            "    step=[8, 11])\n",
            "runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
            "checkpoint_config = dict(interval=3)\n",
            "log_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])\n",
            "custom_hooks = [dict(type='NumClassCheckHook')]\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = 'checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_bbox_mAP-0.398_20200504_163323-30042637.pth'\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "work_dir = './tutorial_exps'\n",
            "seed = 0\n",
            "gpu_ids = range(0, 1)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbKCc1tKg3oj",
        "outputId": "3afb9837-266d-466c-dcd3-5ac1b0df7196"
      },
      "source": [
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.datasets import build_dataloader\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "\n",
        "os.chdir('/content/mmdetection')\n",
        "# Build dataset\n",
        "# print(cfg.data.train)\n",
        "\n",
        "datasets = [build_dataset(cfg.data.train)]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mmdetection/mmdet/datasets/custom.py:157: UserWarning: CustomDataset does not support filtering empty gt images.\n",
            "  'CustomDataset does not support filtering empty gt images.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfi0bOR3haCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b70740e-c02f-4848-a801-69f30902497d"
      },
      "source": [
        "print(datasets[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "HW2_SVHN_Dataset Train dataset with number of images 25933, and instance counts: \n",
            "+-----------+-------+----------+-------+----------+-------+----------+-------+----------+-------+\n",
            "| category  | count | category | count | category | count | category | count | category | count |\n",
            "+-----------+-------+----------+-------+----------+-------+----------+-------+----------+-------+\n",
            "| 0 [0.0]   | 0     | 1 [1.0]  | 10676 | 2 [2.0]  | 7980  | 3 [3.0]  | 6589  | 4 [4.0]  | 5678  |\n",
            "| 5 [5.0]   | 5485  | 6 [6.0]  | 4567  | 7 [7.0]  | 4355  | 8 [8.0]  | 3975  | 9 [9.0]  | 3637  |\n",
            "|           |       |          |       |          |       |          |       |          |       |\n",
            "| 10 [10.0] | 3932  |          |       |          |       |          |       |          |       |\n",
            "+-----------+-------+----------+-------+----------+-------+----------+-------+----------+-------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiYgC_1RNRrd"
      },
      "source": [
        "os.chdir('/content/mmdetection')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZHMTsakwfdo"
      },
      "source": [
        "\n",
        "# Build the detector\n",
        "model = build_detector(cfg.model)\n",
        "# Add an attribute for visualization convenience\n",
        "# model.CLASSES = datasets[0].CLASSES\n",
        "\n",
        "# Create work_dir\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "\n",
        "train_detector(model, datasets, cfg, distributed=False, validate=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}